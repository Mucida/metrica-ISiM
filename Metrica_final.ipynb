{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZjI8YYI5Xal1o1/4n8CM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mucida/metrica-ISiM/blob/main/Metrica_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inicialização"
      ],
      "metadata": {
        "id": "zPHoGlUbkiEh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XRIltRG5d1M",
        "outputId": "26224a53-23df-4329-d456-3c9cdb725f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.0.3-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy>=6.1 (from wordfreq)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.5)\n",
            "Requirement already satisfied: regex>=2021.7.6 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2022.10.31)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.6)\n",
            "Installing collected packages: ftfy, wordfreq\n",
            "Successfully installed ftfy-6.1.1 wordfreq-3.0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import os\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from wordfreq import word_frequency, zipf_frequency\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stopWords(review, remove_stopwords):\n",
        "    stops = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "    review = [w for w in review if not w in stops]\n",
        "    return review"
      ],
      "metadata": {
        "id": "jGs0LgrL5m2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métrica para frases a vulso"
      ],
      "metadata": {
        "id": "friUjKYmklzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#utilziando sempre a palavra de maior frequencia como 1, e multiplicando os valores normalizados pela palavra de maior frequencia\n",
        "#probabilidade de uma palavra estar presente no contexto da frase\n",
        "remove_stopwords = True;\n",
        "frases = []\n",
        "\n",
        "#sents = ['Samuel Holberry was sentenced to 4 years imprisonment with hard labour and died in prison at York Castle on June twenty one',\n",
        "#         'On June 20, Samuel Holberry was sentenced to 4 years in jail for hard work and died in prison at York Castle.',\n",
        "#         'On June 20, Samuel was sentenced to 4 years in jail for hard work and died in prison at York Castle.']\n",
        "##sents = ['He seems gleeful with this news today, so we are going to throw him a gathering to celebreate this great day.','He seems happy with this news today, so we are going to throw him a gathering in celebration of his great day']\n",
        "#sents = [\"I 'll tell thee what, thou damned tripe-visaged rascal, an the child I now go with do miscarry, thou wert better thou hadst struck thy mother, thou paper-faced villain.\",\"the child I now go with do miscarry, thou will be better off having struck your mother than paper-faced villain.\"]\n",
        "#sents = [\"Tu ficou de cócoras\", \"Tu se agachou\",\"Nunca tinha estado melhor.\",\"Nunca estive melhor.\"]\n",
        "sents = ['Samuel Holberry was sentenced to 4 years imprisonment with hard labour and died in prison at York Castle on June twenty one',\n",
        "'However the first 15 minutes of each meeting are available for members of the public to voice opinions or raise questions.',\n",
        "'Terms such as \"undies\" for underwear and \"movie\" for \"moving picture\" are oft-heard terms in English.',\n",
        "'I am very fatigued today.',\n",
        "'He seems gleeful with this news today, so we are going to throw him a gathering to celebreate this great day.',\n",
        "'The single most powerful asset we all have is our mind. If it is trained well, it can create enormous wealth',\n",
        "'Fives is a British sport believed to derive from the same origins as many racquet sports.',\n",
        "'many mosques will not enforce rules, but both men and women when there must follow these rules.',\n",
        "'the worlds first MMA league was the International Fight League, and American mixed martial arts.']\n",
        "\n",
        "\n",
        "\n",
        "sents = [\n",
        "'Once you have read the guidance booklet and are sure you meet the criteria, you can download and complete the application form.',\t'After you have gone through the helpful book and are confident you qualify, you can get the form and fill it out.',\n",
        "'The identification facility enables the radio to be ‘ identified ’ on the control room base station by showing the call sign and premises details on an LCD display.',\t'The ID feature lets the radio be recognized on the control room base station by displaying the call sign and location info on a screen.',\n",
        "'We offer impartial, independent and confidential support to parents and carers who are dissatisfied with the service they have received from a school.',\t'We provide fair, separate, and private help to moms and dads and caregivers who are unhappy with the assistance they got from a school.', 'We offer impartial, independent and confidential help to parents and carers who are unhappy with the service they received from a school.',\n",
        "'If you do not already have a username or password for the ‘ Anycomms ’ system please email the Early Years FEL Census Team.',\t'If you dont have a username or password for the Anycomms system, please send an email to the Early Years FEL Census Team.',\n",
        "'Consultation will also take place with local residents and / or businesses by placing public notices and issuing consultation forms at the site.',\t'We will talk to people who live or work nearby by putting up signs and giving out forms at the location.',\n",
        "'Our team of mechanics are trained to carry out vehicle testing as well as a wide range of vehicle maintenance work and receive regular training and development on new technology.',\t'Our group of car experts are skilled to do car inspections and a variety of car upkeep tasks. They also get frequent education on the latest technology.',\n",
        "'That steps are taken to prevent and control the spread of disease among the animals and that isolation facilities are in place.',\t'We are making sure to stop and manage the spread of sickness between the animals, and we have areas set up for isolating them.', 'Steps are taken to stop and control the spread of disease among animals, and isolation facilities are available',\n",
        "'You should be able to show what the issues are, that you have highlighted concerns to parents / carers and what has been tried.',\t'You need to demonstrate the problems, let parents or caregivers know about your worries, and explain what actions have been taken.',\n",
        "'The majority of the plans are the work of the second William Fairbank, his sons William and Josiah, and Josiah ’ s son, William Fairbank.',\t'Most of the plans were made by William Fairbank II, his sons William and Josiah, and Josiah son, William Fairbank.',\n",
        "'If you disobey this order you will be guilty of contempt of court and may be sent to prison or fined or your assets seized.',\t'If you do not follow this command, you will be in trouble with the court and could end up in jail, have to pay a fine, or lose your belongings.']\n",
        "\n",
        "sents = [\"The Framework allows us to evaluate all family members so that we can determine the appropriate support for families and collaborate with other professionals to assist them.\",\t\"The Framework enables us to assess all family members so that we can identify the right support for families and work together with other professionals to support them.\",\n",
        "\"By controlling how cities are constructed and making sure that Part IIA of the Environmental Protection Act 1990 is followed.\",\t\"Through the town planning development control process and the enforcement of Part IIA of the Environmental Protection Act 1990.\",\n",
        "\"The LEZ helps us and our partners follow the EU's rules for clean air by reducing NO2 and PM10.\",\t\"The aim of the LEZ would be to help our partners and us to comply with European Union Air Quality standards for NO2 and PM10.\",\n",
        "\"If you work in a job where you need to protect adults, you can learn more by taking our safeguarding adults' training or studying the Mental Capacity Act and Deprivation of Liberty Safeguards.\",\t\"If you are a professional and would like to find out more information on safeguarding adults please see our safeguarding adults' training, or the Mental Capacity Act and Deprivation of Liberty Safeguards.\",\n",
        "\"To keep kids and teens safe, the law says that if you're taking care of someone else's child, you have to tell the people in charge of helping children in your area.\",\t\"To keep children and young people safe, the Government has made it the law for anyone who is looking after someone else's child to inform their local children's services.\",\n",
        "\"We've spent a lot of money to make our council homes safer from fires and we've been improving them for the last 5 years.\",\t\"We have already spent millions on fire safety in our council homes and improvement works have been carried out over the last 5 years.\",\n",
        "\"Sheffield Wednesday FC, nicknamed 'The Owls' due to their former stadium at Owlerton, was established in Sheffield in 1867.\",\t\"Sheffield Wednesday Football Club, also known as' The Owls' (so-called because the team played at Owlerton from 1899) formed in 1867 in Sheffield.\",\n",
        "\"If you want to know more about the EU Services Directive and Points of Single Contact for other countries in the EU, go to the European Commission's website.\",\t\"For full information on the EU Services Directive and Points of Single Contact for other member states from the European Commission.\",\n",
        "\"We have already spent millions on fire safety in our council homes and improvement works have been carried out over the last 5 years.\", \"We have already expended millions on fire safety in our council homes, and improvement projects have been implemented over the past 5 years.\"]\n",
        "\n",
        "\n",
        "for s in sents:\n",
        "  dicionario = {}\n",
        "  m = 0.0\n",
        "  tokens = s.split()\n",
        "  dicionario[\"frase\"]=s\n",
        "  if remove_stopwords:\n",
        "        tokens = stopWords(tokens, remove_stopwords)\n",
        "  nt = len(tokens)\n",
        "  for w in tokens:\n",
        "    contagem = zipf_frequency (w, 'en')\n",
        "    print(w, \" \", contagem)\n",
        "    if contagem <1: contagem =1\n",
        "    m+= contagem\n",
        "\n",
        "  #m=m/pow(nt,1.19) //correto\n",
        "  m=m/pow(nt,1.27)\n",
        "  #m = math.log10(m)\n",
        "\n",
        "  dicionario[\"pontos\"]= round(m,4)\n",
        "\n",
        "  frases.append(dicionario)\n",
        "  print(\"{}:\\t{}\".format(s,m))"
      ],
      "metadata": {
        "id": "Voq7lbJ45mdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métrica que le um corpus de paráfrase e gera o corpus ordenado"
      ],
      "metadata": {
        "id": "Wm9lVk5akqGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords = False;\n",
        "frases = []\n",
        "\n",
        "#f = open(\"/content/comparar4-200.txt\",\"r\")\n",
        "f = open(\"/content/frases-traduzidas.txt\",\"r\")\n",
        "#f = open(\"/content/asset-original-com-sim-grande.txt\",\"r\")\n",
        "sents = [line.strip().split(\"\\t\") for line in  f]\n",
        "f.close()\n",
        "print(len(sents))\n",
        "\n",
        "with open('/content/saida.txt', 'w') as f:\n",
        "    for p in sents:\n",
        "        for s in p:\n",
        "            dicionario = {}\n",
        "            m = 0.0\n",
        "            tokens = s.split()\n",
        "            dicionario[\"frase\"]=s\n",
        "            if remove_stopwords:\n",
        "                tokens = stopWords(tokens, remove_stopwords)\n",
        "            nt = len(tokens)\n",
        "            for w in tokens:\n",
        "                contagem = zipf_frequency (w, 'pt')\n",
        "                #print(w, \" \", contagem)\n",
        "                if contagem <1: contagem =1\n",
        "                m+= contagem\n",
        "\n",
        "            m=m/pow(nt,1.18)\n",
        "            #m = math.log10(m)\n",
        "\n",
        "            dicionario[\"pontos\"]= round(m,4)\n",
        "\n",
        "            frases.append(dicionario)\n",
        "            #print(\"{}:\\t{}\".format(s,m))\n",
        "            f.write('{}\\t{}\\n'.format(s,m))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_1hhtyAWbPE",
        "outputId": "db2be506-f83c-4e05-845f-651a04e41d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar arquivos após métrica\n"
      ],
      "metadata": {
        "id": "SkSOgDjiWOnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/saida.txt\",\"r\")\n",
        "pairs = [line.strip().split(\"\\t\") for line in  f]\n",
        "f.close()\n",
        "\n",
        "tamCorpus = len(pairs)/2\n",
        "print(len(pairs)/2)\n",
        "\n",
        "\n",
        "with open('/content/complexo-simples-pontuacao-comStop.txt', 'w') as f:\n",
        "    count = 0\n",
        "    count2 = 0\n",
        "    count3 = 0\n",
        "    for i in range(0,len(pairs),2):\n",
        "        p0 = pairs[i][1]\n",
        "        p1 = pairs[i+1][1]\n",
        "        if p0 > p1:\n",
        "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(pairs[i+1][0],pairs[i][0],p1,p0,1))\n",
        "            count2+=1\n",
        "        elif p1 >= p0:\n",
        "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(pairs[i][0],pairs[i+1][0],p0,p1,0))\n",
        "            count+=1\n",
        "        else: continue\n",
        "    print(\"sem trocas\", count)\n",
        "    print(\"com trocas \", count2)\n",
        "    print(\"empates \", count3)\n",
        "    print(\"acerto: \" , count*100/tamCorpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJEma3-Ccos5",
        "outputId": "dc43f1dd-88a0-404a-db71-600b340eecea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "357.0\n",
            "sem trocas 278\n",
            "com trocas  79\n",
            "empates  0\n",
            "acerto:  77.87114845938375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/saida.txt\",\"r\")\n",
        "pairs = [line.strip().split(\"\\t\") for line in  f]\n",
        "f.close()\n",
        "\n",
        "print(len(pairs)/2)\n",
        "\n",
        "with open('/content/complexo-simples2.txt', 'w') as f:\n",
        "    count = 1\n",
        "    for i in range(0,len(pairs),2):\n",
        "        p0 = pairs[i][1]\n",
        "        p1 = pairs[i+1][1]\n",
        "        if p0 > p1:\n",
        "            f.write('{}\\t{}\\n'.format(pairs[i+1][0],pairs[i][0]))\n",
        "        elif p1 > p0:\n",
        "            f.write('{}\\t{}\\n'.format(pairs[i][0],pairs[i+1][0]))\n",
        "        else: continue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5RBOz1Eoe2J",
        "outputId": "a78942ed-828e-4a22-f392-4b5e3a324e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "359.0\n",
            "time: 10.8 ms (started: 2022-10-05 18:18:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textstat\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xocAFsYNgby",
        "outputId": "1a94bcdf-02d8-4deb-c46f-9390499b3af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.9/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.9/dist-packages (from textstat) (0.14.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.parse import stanford\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from textstat import flesch_kincaid_grade\n",
        "import math\n",
        "\n",
        "def calculate_values(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Tokenize the sentence into sentences\n",
        "    sentences = sent_tokenize(sentence)\n",
        "\n",
        "    # Count the number of clauses by finding the number of sentences\n",
        "    num_clauses = len(sentences)\n",
        "\n",
        "\n",
        "    # Count the number of words in the sentence\n",
        "    num_words = len(words)\n",
        "\n",
        "    # Calculate C(S) and L(S)\n",
        "    C_S = num_clauses / len(sentences)\n",
        "    L_S = num_words / num_clauses\n",
        "\n",
        "    # Calculate F(S)\n",
        "    F_S = flesch_kincaid_grade(sentence)\n",
        "\n",
        "    return (C_S, L_S, F_S)\n",
        "\n",
        "# Example usage\n",
        "#sentence = \"We have already spent millions on fire safety in our council homes and improvement works have been carried out over the last 5 years.\"\n",
        "\n",
        "\n",
        "remove_stopwords = False;\n",
        "frases = []\n",
        "\n",
        "#f = open(\"/content/comparar4-200.txt\",\"r\")\n",
        "#f = open(\"/content/turk-grande-original.txt\",\"r\")\n",
        "#f = open(\"/content/parallel200.txt\",\"r\")\n",
        "f = open(\"/content/gpt-200-modificando-erradas.txt\",\"r\")\n",
        "sents = [line.strip().split(\"\\t\") for line in  f]\n",
        "f.close()\n",
        "print(len(sents))\n",
        "\n",
        "with open('/content/saida.txt', 'w') as f:\n",
        "    for p in sents:\n",
        "        for s in p:\n",
        "            dicionario = {}\n",
        "            m = 0.0\n",
        "            C_S, L_S, F_S = calculate_values(s)\n",
        "            #print(F_S)\n",
        "            tokens = s.split()\n",
        "            dicionario[\"frase\"]=s\n",
        "            if remove_stopwords:\n",
        "                tokens = stopWords(tokens, remove_stopwords)\n",
        "            nt = len(tokens)\n",
        "            for w in tokens:\n",
        "                contagem = zipf_frequency (w, 'en')\n",
        "                #print(w, \" \", contagem)\n",
        "                if contagem <1: contagem =1\n",
        "                m+= contagem\n",
        "            #m = (m/(L_S*F_S))\n",
        "            m=m/pow(nt,1.19)\n",
        "            #m = math.log10(m)\n",
        "\n",
        "            dicionario[\"pontos\"]= round(m,4)\n",
        "\n",
        "            frases.append(dicionario)\n",
        "            #print(\"{}:\\t{}\".format(s,m))\n",
        "            f.write('{}\\t{}\\n'.format(s,m))\n",
        "\n",
        "\n",
        "\n",
        "f = open(\"/content/saida.txt\",\"r\")\n",
        "pairs = [line.strip().split(\"\\t\") for line in  f]\n",
        "f.close()\n",
        "\n",
        "tamCorpus = len(pairs)/2\n",
        "print(len(pairs)/2)\n",
        "\n",
        "\n",
        "with open('/content/complexo-simples-pontuacao-comStop.txt', 'w') as f:\n",
        "    count = 0\n",
        "    count2 = 0\n",
        "    count3 = 0\n",
        "    for i in range(0,len(pairs),2):\n",
        "        p0 = pairs[i][1]\n",
        "        p1 = pairs[i+1][1]\n",
        "        if p0 > p1:\n",
        "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(pairs[i+1][0],pairs[i][0],p1,p0,1))\n",
        "            count2+=1\n",
        "        elif p1 >= p0:\n",
        "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(pairs[i][0],pairs[i+1][0],p0,p1,0))\n",
        "            count+=1\n",
        "        elif p1 == p0:\n",
        "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(pairs[i][0],pairs[i+1][0],p0,p1,-100))\n",
        "            count3+=1\n",
        "        else: continue\n",
        "    print(\"sem trocas\", count)\n",
        "    print(\"com trocas \", count2)\n",
        "    print(\"empates \", count3)\n",
        "    print(\"acerto: \" , count*100/tamCorpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2ON_aIcMv3y",
        "outputId": "e2fb4941-2908-430d-e6c6-c0c1eb8ae76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "200.0\n",
            "sem trocas 188\n",
            "com trocas  12\n",
            "empates  0\n",
            "acerto:  94.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gN3-8oiMyiM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}